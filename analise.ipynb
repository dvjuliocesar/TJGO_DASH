{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importando bibliotecas\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import datetime as dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classe para manipulação e análise de dados\n",
    "class AnaliseDados:\n",
    "    \n",
    "    def __init__(self, caminho_arquivo: str): \n",
    "        \"\"\" \n",
    "        Inicializa a classe com um DataFrame e o caminho do arquivo csv.\n",
    "    \n",
    "        Args:\n",
    "            caminho_arquivo: Caminho para o arquivo csv.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.df = pd.read_csv('C:/Users/Sara de Castro/Desktop/TJ-GO/UFG/IntroducaoProgramacao/ProjetoPython1.3/Processos_Inhumas.csv')\n",
    "        self.nome_arquivo = 'C:/Users/Sara de Castro/Desktop/TJ-GO/UFG/IntroducaoProgramacao/ProjetoPython1.3/Processos_Inhumas.csv'\n",
    "\n",
    "    def visualizar_dataframe(self, n: int = 5) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Exibe uma visualização do DataFrame.\n",
    "        \n",
    "        Args:\n",
    "            n (int): Número de linhas a serem exibidas (padrão: 5).\n",
    "        \n",
    "        Retorns:\n",
    "            DataFrame com as primeiras n linhas.\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.df.head(n)\n",
    "    \n",
    "    \n",
    "    def listar_colunas(self) -> list[str]:\n",
    "        \"\"\"\n",
    "        Lista todas as colunas disponíveis no DataFrame.\n",
    "        \"\"\"\n",
    "        colunas = list(self.df.columns)\n",
    "        print(\"Colunas disponíveis:\")\n",
    "        for i, coluna in enumerate(colunas, 1):\n",
    "            print(f\"{i}. {coluna}\")\n",
    "        return colunas\n",
    "    \n",
    "    \n",
    "    def selecionar_colunas(self, colunas: list[str]) -> pd.DataFrame:\n",
    "        \"\"\" \n",
    "        Retorna um DataFrame apenas com as colunas selecionadas.\n",
    "    \n",
    "        Args:\n",
    "            colunas: Lista com os nomes das colunas desejadas.\n",
    "        \"\"\"\n",
    "        return self.df[colunas] \n",
    "    \n",
    "        \n",
    "    def distribuidos_por_ano(self, ano: int) -> int:\n",
    "        \"\"\"\n",
    "        Conta quantas datas existem de um ano específico na coluna 'data_distribuicao',\n",
    "        ignorando valores NaN.\n",
    "        \n",
    "        Args:\n",
    "            ano: Ano específico para filtrar\n",
    "            \n",
    "        Returns:\n",
    "            Número de datas no ano especificado\n",
    "        \"\"\"\n",
    "        # Verifica se a coluna existe\n",
    "        coluna_data = 'data_distribuicao'\n",
    "        if coluna_data not in self.df.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna_data}' não existe no DataFrame\")\n",
    "        \n",
    "        try:\n",
    "            # Converte coluna para datetime e lida com NaN\n",
    "            datas = pd.to_datetime(self.df[coluna_data], errors='coerce')\n",
    "            \n",
    "            # Filtra por ano e conta valores não-nulos\n",
    "            contagem = datas[datas.dt.year == ano].count()\n",
    "            \n",
    "            return contagem\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Erro ao processar a coluna '{coluna_data}': {str(e)}\")\n",
    "\n",
    "    \n",
    "    def baixados_por_ano(self, ano: int) -> int:\n",
    "        \"\"\"\n",
    "        Conta quantas datas existem de um ano específico na coluna 'data_baixa',\n",
    "        ignorando valores NaN.\n",
    "        \n",
    "        Args:\n",
    "            ano: Ano específico para filtrar\n",
    "            \n",
    "        Returns:\n",
    "            Número de datas no ano especificado\n",
    "        \"\"\"\n",
    "        # Verifica se a coluna existe\n",
    "        coluna_data = 'data_baixa'\n",
    "        if coluna_data not in self.df.columns:\n",
    "            raise ValueError(f\"A coluna '{coluna_data}' não existe no DataFrame\")\n",
    "        \n",
    "        try:\n",
    "            # Converte coluna para datetime e lida com NaN\n",
    "            datas = pd.to_datetime(self.df[coluna_data], errors='coerce')\n",
    "            \n",
    "            # Filtra por ano e conta valores não-nulos\n",
    "            contagem = datas[datas.dt.year == ano].count()\n",
    "            \n",
    "            return contagem\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Erro ao processar a coluna '{coluna_data}': {str(e)}\")\n",
    "            \n",
    "    \n",
    "    def pendentes_por_ano(self, ano: int) -> int:\n",
    "        \"\"\"\n",
    "        Conta apenas o número total de valores NaN na coluna 'data_baixa' filtrados \n",
    "        pelo ano especificado da coluna 'data_distribuicao' que tenham o mesmo processo_id.\n",
    "        \n",
    "        Args:\n",
    "            ano: Ano específico para filtrar na coluna 'data_distribuicao'\n",
    "            \n",
    "        Returns:\n",
    "            Número inteiro representando a contagem total de NaN na coluna 'data_baixa'\n",
    "        \"\"\"\n",
    "        # Verifica se as colunas necessárias existem\n",
    "        colunas_necessarias = ['data_distribuicao', 'data_baixa', 'processo_id']\n",
    "        for coluna in colunas_necessarias:\n",
    "            if coluna not in self.df.columns:\n",
    "                raise ValueError(f\"A coluna '{coluna}' não existe no DataFrame\")\n",
    "        \n",
    "        try:\n",
    "            # Cria uma cópia do DataFrame para manipulação\n",
    "            df_temp = self.df.copy()\n",
    "            \n",
    "            # Converte a coluna data_distribuicao para datetime\n",
    "            df_temp['data_dist_dt'] = pd.to_datetime(df_temp['data_distribuicao'], errors='coerce')\n",
    "            \n",
    "            # Extrai o ano da coluna data_distribuicao\n",
    "            df_temp['ano_dist'] = df_temp['data_dist_dt'].dt.year\n",
    "            \n",
    "            # Filtra por ano específico na coluna data_distribuição\n",
    "            df_ano = df_temp[df_temp['ano_dist'] == ano]\n",
    "            \n",
    "            # Conta valores NaN na coluna data_baix para os registros filtrados\n",
    "            contagem_nan = df_ano['data_baixa'].isna().sum()\n",
    "            \n",
    "            return contagem_nan\n",
    "            \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Erro ao analisar os dados: {str(e)}\")\n",
    "    \n",
    "    def taxa_congestionamento_por_ano(self, ano: int) -> float:\n",
    "        \"\"\"\n",
    "        Calcula a taxa de congestionamento para um ano específico.\n",
    "        \n",
    "        Args:\n",
    "            ano: Ano para calcular a taxa de congestionamento\n",
    "            \n",
    "        Returns:\n",
    "            Taxa de congestionamento como um valor entre 0 e 1\n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Obter total de processos baixados no ano\n",
    "            # Substitua \"obter_total_baixados_por_ano\" pelo nome do seu método existente\n",
    "            total_baixados = self.baixados_por_ano(ano)\n",
    "            \n",
    "            # Obter total de processos pendentes no ano\n",
    "            # Substitua \"obter_total_pendentes_por_ano\" pelo nome do seu método existente\n",
    "            total_pendentes = self.pendentes_por_ano(ano)\n",
    "            \n",
    "            # Verificar se os denominadores são válidos\n",
    "            if (total_baixados + total_pendentes) == 0:\n",
    "                return 0.0  # ou raise ValueError(\"Divisão por zero: não há processos baixados nem pendentes\")\n",
    "            \n",
    "            # Calcular a taxa de congestionamento\n",
    "            taxa_congestionamento = total_pendentes / (total_baixados + total_pendentes)\n",
    "            \n",
    "            # Arredondar para 4 casas decimais\n",
    "            taxa_congestionamento = round(taxa_congestionamento, 4)\n",
    "            \n",
    "            return taxa_congestionamento\n",
    "        \n",
    "        except Exception as e:\n",
    "            raise ValueError(f\"Erro ao calcular a taxa de congestionamento para o ano {ano}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instanciando a classe\n",
    "analise1 = AnaliseDados('C:/Users/jcpsrodrigues/Desktop/TJ-GO/Projeto1/Processos_Inhumas.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualizando Dataframe\n",
    "display(analise1.visualizar_dataframe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas disponíveis:\n",
      "1. processo_id\n",
      "2. comarca\n",
      "3. comarca_id\n",
      "4. entrancia\n",
      "5. serventia\n",
      "6. codg_serventia_cnj\n",
      "7. vara_oficial_id\n",
      "8. origem\n",
      "9. is_conhecimento\n",
      "10. grupo_cnj_id\n",
      "11. is_recurso\n",
      "12. processo\n",
      "13. natureza\n",
      "14. codg_natureza\n",
      "15. fase\n",
      "16. data_fase\n",
      "17. data_distribuicao\n",
      "18. data_baixa\n",
      "19. data_arquivo\n",
      "20. data_publicacao_acordao\n",
      "21. data_arquivo_provisorio\n",
      "22. data_primeiro_julgamento\n",
      "23. data_receb_prim_recurso\n",
      "24. data_retorno_ultimo_recurso\n",
      "25. data_transito_julgado\n",
      "26. data_suspensao\n",
      "27. id_pena_exe_tipo\n",
      "28. is_maria_penha\n",
      "29. is_proc_adm_desp\n",
      "30. is_exec_fiscal\n",
      "31. is_exec_titulo_extra\n",
      "32. is_exec_judicial\n",
      "33. is_acao_improbidade_corrupcao\n",
      "34. is_suspenso\n",
      "35. juiz\n",
      "36. instancia_id\n",
      "37. tipo_area\n",
      "38. codg_fase\n",
      "39. codg_classe\n",
      "40. nome_area_acao\n",
      "41. nome_serventia\n",
      "42. info_execucao_sentenca\n",
      "43. tipo_serventia\n",
      "44. identificador_processo_origem\n",
      "45. identificador_processo\n",
      "46. valor_acao\n",
      "47. grupo_res76_id\n",
      "48. grupo_cnj\n",
      "49. codg_area_acao\n",
      "50. data_primeira_audiencia\n",
      "51. data_baixa_considerada\n",
      "52. nome_serventia_processo\n",
      "53. codg_serventia_processo\n",
      "54. codg_comarca_origem\n",
      "55. nome_comarca_origem\n",
      "56. codg_atividade\n",
      "57. data_remessa_instancia_inferior\n",
      "58. is_desconsiderar_estatistica\n",
      "59. is_acao_coletiva\n",
      "60. data_julgamento_considerada\n",
      "61. gabinete\n",
      "62. codg_gabinete_cnj\n",
      "63. gabinete_codigo_cnj\n",
      "64. vara_oficial_codigo_cnj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['processo_id',\n",
       " 'comarca',\n",
       " 'comarca_id',\n",
       " 'entrancia',\n",
       " 'serventia',\n",
       " 'codg_serventia_cnj',\n",
       " 'vara_oficial_id',\n",
       " 'origem',\n",
       " 'is_conhecimento',\n",
       " 'grupo_cnj_id',\n",
       " 'is_recurso',\n",
       " 'processo',\n",
       " 'natureza',\n",
       " 'codg_natureza',\n",
       " 'fase',\n",
       " 'data_fase',\n",
       " 'data_distribuicao',\n",
       " 'data_baixa',\n",
       " 'data_arquivo',\n",
       " 'data_publicacao_acordao',\n",
       " 'data_arquivo_provisorio',\n",
       " 'data_primeiro_julgamento',\n",
       " 'data_receb_prim_recurso',\n",
       " 'data_retorno_ultimo_recurso',\n",
       " 'data_transito_julgado',\n",
       " 'data_suspensao',\n",
       " 'id_pena_exe_tipo',\n",
       " 'is_maria_penha',\n",
       " 'is_proc_adm_desp',\n",
       " 'is_exec_fiscal',\n",
       " 'is_exec_titulo_extra',\n",
       " 'is_exec_judicial',\n",
       " 'is_acao_improbidade_corrupcao',\n",
       " 'is_suspenso',\n",
       " 'juiz',\n",
       " 'instancia_id',\n",
       " 'tipo_area',\n",
       " 'codg_fase',\n",
       " 'codg_classe',\n",
       " 'nome_area_acao',\n",
       " 'nome_serventia',\n",
       " 'info_execucao_sentenca',\n",
       " 'tipo_serventia',\n",
       " 'identificador_processo_origem',\n",
       " 'identificador_processo',\n",
       " 'valor_acao',\n",
       " 'grupo_res76_id',\n",
       " 'grupo_cnj',\n",
       " 'codg_area_acao',\n",
       " 'data_primeira_audiencia',\n",
       " 'data_baixa_considerada',\n",
       " 'nome_serventia_processo',\n",
       " 'codg_serventia_processo',\n",
       " 'codg_comarca_origem',\n",
       " 'nome_comarca_origem',\n",
       " 'codg_atividade',\n",
       " 'data_remessa_instancia_inferior',\n",
       " 'is_desconsiderar_estatistica',\n",
       " 'is_acao_coletiva',\n",
       " 'data_julgamento_considerada',\n",
       " 'gabinete',\n",
       " 'codg_gabinete_cnj',\n",
       " 'gabinete_codigo_cnj',\n",
       " 'vara_oficial_codigo_cnj']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Listando as colunas disponíveis\n",
    "analise1.listar_colunas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colunas_selecionadas = analise1.selecionar_colunas(['processo_id', 'nome_area_acao', 'data_distribuicao', 'data_baixa'])\n",
    "display(colunas_selecionadas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribuídos em 2018: 956\n"
     ]
    }
   ],
   "source": [
    "# Contando distribuídos em 2018\n",
    "distribuidos_2018 = analise1.distribuidos_por_ano(2018)\n",
    "print(f\"Distribuídos em 2018: {distribuidos_2018}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baixados em 2018: 0\n"
     ]
    }
   ],
   "source": [
    "# Contando baixados em 2018\n",
    "baixados_2018 = analise1.baixados_por_ano(2018)\n",
    "print(f\"Baixados em 2018: {baixados_2018}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Contar pendentes em data_baix para registros com data_dist em 2018\n",
    "pendentes_2018 = analise1.pendentes_por_ano(2018)\n",
    "print(f\"Pendentes em 2018 = {pendentes_2018}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Taxa de Congestionamento por ano\n",
    "taxa_congestionamento_2018 = analise1.taxa_congestionamento_por_ano(2018)\n",
    "print(f\"Taxa de Congestionamento em 2018: {taxa_congestionamento_2018:.2%}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
